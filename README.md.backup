# Recent Works in Machine Learning focused on Mental Health

The survey work in [TOCHI2020](https://dl.acm.org/doi/10.1145/3398069) is the initial inspiration. This repository contains link to available datasets and tools along with the research papers which focuses on this research domain.

The current and future direction for the application of Machine Learning on Mental Health is enlisted here. Please help us grow the list and contact us for collaborative works.


## Datasets

Datasets publicly available on Mental Health. There are many datasets which are not released to public. For example, the data collected using Tweeter API; data collected from mobile applications like **Emotion Sense**, **StudentLife** and **SNAPSHOT** etc.

The datasets are usually collected using mobile sensors, audio/video sessions, social media, chats, suicide notes, health record, questionnaire, human-agent interation etc.

| Dataset Name | Description | 
|---           |   :----     |
| Analysis Interview Corpus [(DAIC-WOZ)](https://dcapswoz.ict.usc.edu/) & Extended Distress Analysis Interview Corpus dataset (E-DAIC) <br /> **Year: 2014** | The Distress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ) database is part of a larger corpus, the Distress Analysis Interview Corpus [(DAIC)](https://www.aclweb.org/anthology/L14-1421/), that contains clinical interviews designed to support the diagnosis of psychological distress conditions such as anxiety, depression, and post-traumatic stress disorder. These interviews were collected as part of a larger effort to create a computer agent that interviews people and identifies verbal and nonverbal indicators of mental illness. Data collected include audio and video recordings and extensive questionnaire responses; this part of the corpus includes the Wizard-of-Oz interviews, conducted by an animated virtual interviewer called Ellie, controlled by a human interviewer in another room. Data has been transcribed and annotated for a variety of verbal and non-verbal features. [AVEC2016](https://doi.org/10.1145/2988257.2988258) | 
| [AVEC2013](https://doi.org/10.1145/2512530.2512533)  <br /> **Year: 2013**  | The challenge uses a subset of the audio-visual depressive language corpus (AViD Corpus), which includes 340 video clips of subjects performing a Human-Computer Interaction task while being recorded by a webcam and a microphone. | 
| [EASE](https://ieeexplore.ieee.org/document/8015015) dataset  <br /> **Year: 2017** | The Engagement Arousal Self-Efficacy (EASE) multimodal dataset contains facial and audio data, physiological signals and selfreports. The data was collected from subjects while undergoing a web-based trauma-recovery treatment. The web-based intervention consisted of 3 sessions, with 2 out of 6 possible modules in each. |    
|[Depresjon](https://datasets.simula.no/depresjon/) Dataset|  A publicly available dataset containing motor activity measurements from participants wearing an actigraph watch at their right wrist. The actigraph watch measures activity by using a piezoelectric accelerometer that is programmed to record the integration of intensity, amount and duration of movement in all directions. The sampling frequency was 32Hz. [Paper](https://doi.org/10.1145/3204949.3208125)  |
| English Longitudinal Study of Ageing [(ELSA)](https://www.elsa-project.ac.uk/) | Provides psychological and mental health data on older adults as indicators of depression | 


## Recent Works

For the promising papers which are recent, do the following exercise as well:

- Problem being solved in the paper
- Positive points/strengths of the technique
- Weaknesses of the technique
- Points skipped, missed, ignored that could've been taken into account to make a better paper.
Dataset used 

Look up the top venues in this area: conferences like HCI, CHI and journals like IEEE TOCHI, Transactions on Affective Computing

